{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "722178ed-e1c5-4348-ac97-144cf339b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.utils as utils\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68abed00-2d14-40d3-bc0d-c5d304648970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'> chr1,+,897185,897285; class:0\\n'\n",
      "b'TGCCTCTCGGTGCCCCGTAGACTCTGCTCCCAGCCGCCAGTCTCCTGCAGCTGAATGGCG\\n'\n",
      "b'TCCGAGACGCTTGCTGCAAGTTTCTACTGAGTCAGCTCGAC\\n'\n",
      "b'> chr1,+,897570,897670; class:0\\n'\n",
      "b'CTGGGCCCCCCAGGAGCCTCGTCTGTGGCTCCTGACTCTGCTCGGCCCCTCCCAGTATGA\\n'\n",
      "b'ACACTCAGCCCCCACCTGCTAACCCTCCCTCCTAGGCATCT\\n'\n",
      "b'> chr1,+,898779,898879; class:0\\n'\n",
      "b'GCCGGAGGTGTCCATGGGCACAAGGCGAAGCTGCCTGGGTGTGGCCGCCTTGCATGGACT\\n'\n",
      "b'CCTGTACTCGGCCGGCGGCTATGACGGGGCCTCCTGCCTGA\\n'\n",
      "b'> chr1,+,899530,899630; class:0\\n'\n"
     ]
    }
   ],
   "source": [
    "a_file = gzip.open(\"../iDeepS/datasets/clip/1_PARCLIP_AGO1234_hg19/30000/training_sample_0/sequences.fa.gz\", \"rb\")\n",
    "contents = a_file.readlines()\n",
    "\n",
    "for i in range(10):\n",
    "    print(contents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e43435b-adb0-4177-9482-accc9759e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_helper(file_path):\n",
    "    res = []\n",
    "    with gzip.open(file_path, \"rb\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = str(line)[2:-3]\n",
    "            \n",
    "            if line.startswith(\">\"):\n",
    "                indicator = 0\n",
    "                tmp = []\n",
    "                loc, y = line.strip().split(\";\")\n",
    "                chr_num, sign, start, end = loc[2:].split(\",\")\n",
    "                tmp.extend([chr_num, sign, int(start), int(end), y[-1]])\n",
    "            \n",
    "            else:\n",
    "                indicator += 1\n",
    "                tmp.append(line)\n",
    "                if indicator == 2:\n",
    "                    res.append(tmp)\n",
    "    df = pd.DataFrame(res, columns = [\"chr_num\", \"sign\", \"start\", \"end\", \"y\", \"seq_part1\", \"seq_part2\"])\n",
    "    df[\"seq\"] = df[\"seq_part1\"] + df[\"seq_part2\"]\n",
    "    df[\"y\"] = df[\"y\"].astype(int)\n",
    "    return df\n",
    "                \n",
    "\n",
    "def embed(sequence, instance_len, instance_stride):\n",
    "    instance_num = int((len(sequence) - instance_len) / instance_stride) + 1\n",
    "    bag = []\n",
    "    for i in range(instance_num):\n",
    "        instance = sequence[i * instance_stride:i * instance_stride + instance_len]\n",
    "        instance = one_hot_encode(instance)\n",
    "        bag.append(instance)\n",
    "    bag = np.stack(bag).astype(float)\n",
    "    return bag\n",
    "\n",
    "def one_hot_encode(seq):\n",
    "    mapping = dict(zip(\"ACGTN\", range(5)))\n",
    "    seq2 = [mapping[i] for i in seq]\n",
    "    return np.eye(5)[seq2]\n",
    "\n",
    "def create_bag(seqs, instance_len=40, instance_stride=5):\n",
    "    bags = []\n",
    "    for seq in seqs:\n",
    "        bags.append(embed(seq, instance_len, instance_stride)) \n",
    "        \n",
    "    return np.array(bags).astype(float)\n",
    "\n",
    "class LibriSamples(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        df = read_file_helper(data_path)\n",
    "        df[\"seq\"] = df[\"seq_part1\"] + df[\"seq_part2\"]\n",
    "        self.X, self.Y = create_bag(df[\"seq\"]), df[\"y\"].to_numpy()\n",
    "        \n",
    "        assert len(self.X) == len(self.Y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.X[item], self.Y[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33c1f01f-2acb-463a-aaf7-1fc4cc489a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13, 40, 5]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"../iDeepS/datasets/clip/1_PARCLIP_AGO1234_hg19/30000/training_sample_0/sequences.fa.gz\"\n",
    "valid_data_path = \"../iDeepS/datasets/clip/9_PARCLIP_ELAVL1MNASE_hg19/30000/test_sample_0/sequences.fa.gz\"\n",
    "batch_size = 1\n",
    "\n",
    "train_data = LibriSamples(train_data_path)\n",
    "valid_data = LibriSamples(valid_data_path)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "for x, y in train_loader:\n",
    "    # print(x, y)\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6545462a-e06a-4cec-8f74-bf0ce062011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakRM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv2d(13, 32, kernel_size = 15, padding=7, stride=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(32, 16, kernel_size = 5, padding=2, stride=1),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "     \n",
    "        self.attention_v = nn.Sequential(\n",
    "            nn.Linear(640, 256),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.attention_u = nn.Sequential(\n",
    "            nn.Linear(640, 256),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.part_1 = nn.Sequential(\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "        self.cls =  nn.Sequential(\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs, training=True, mask=None):\n",
    "        embedding = self.embedding(inputs)\n",
    "        \n",
    "        attention_v = self.attention_v(embedding)\n",
    "        attention_u = self.attention_v(embedding)\n",
    "        \n",
    "        print(attention_u.shape, attention_v.shape)\n",
    "        gated_attention = self.part_1(torch.mul(attention_u, attention_v).permute((1, 0)))\n",
    "        \n",
    "        print(embedding.shape, gated_attention.shape)\n",
    "        bag_probability = torch.matmul(gated_attention, embedding)\n",
    "        \n",
    "        return bag_probability, gated_attention\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0da7d3ab-88ef-41c7-b57b-2212eef0295e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13, 5, 40])\n",
      "torch.Size([1, 256]) torch.Size([1, 256])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (256x1 and 256x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28709/2841300213.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_28709/1946564875.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mgated_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpart_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgated_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x1 and 256x1)"
     ]
    }
   ],
   "source": [
    "network = WeakRM().cuda()\n",
    "for x, y in train_loader:\n",
    "    print(x.permute((0, 1, 3, 2)).shape)\n",
    "    x = x.permute((0, 1, 3, 2)).float().cuda()\n",
    "    # print(x)\n",
    "    output = network(x)\n",
    "    print(output[0].shape, output[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3697a5f0-29af-42c7-a661-e84e0eeeebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_file(\"../iDeepS/datasets/clip/1_PARCLIP_AGO1234_hg19/30000/training_sample_0/sequences.fa.gz\")\n",
    "df[\"seq\"] = df[\"seq_part1\"] + df[\"seq_part2\"]\n",
    "a, b = create_bag(df[\"seq\"], df[\"y\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20288411-86d0-4ea1-adfb-8fcb2b73474f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390000, 40, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5427a37-ac29-4245-895d-f88b0cf8d227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb503342-ccf3-449c-a244-eceaf8550ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= read_file(\"../iDeepS/datasets/clip/1_PARCLIP_AGO1234_hg19/30000/training_sample_0/sequences.fa.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0515f506-7f66-44d1-9a72-34ea552b2000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac0ff824-5aec-4ce1-a937-4c76d361c061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"seq\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7410a5c-dbc2-4bf7-82a8-3d4c664c9dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr_num</th>\n",
       "      <th>sign</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>seq_part1</th>\n",
       "      <th>seq_part2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>8000</td>\n",
       "      <td>8000</td>\n",
       "      <td>8000</td>\n",
       "      <td>8000</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chr_num  sign  start   end  seq_part1  seq_part2\n",
       "y                                                  \n",
       "0     8000  8000   8000  8000       8000       8000\n",
       "1     2000  2000   2000  2000       2000       2000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_file(\"../iDeepS/datasets/clip/9_PARCLIP_ELAVL1MNASE_hg19/30000/test_sample_0/sequences.fa.gz\")\n",
    "df.groupby(\"y\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8c1680-a75f-49c8-a5cd-ae1aac217b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
